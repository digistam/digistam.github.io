 <meta name=”robots” content=”noindex,nofollow”/>
  <a href=../index.html>Back to home</a>
<hr/>
<h1>Investigating web servers</h1>
<p>Most organizations consider their web presence to be an extension of themselves. Organizations create their web presence on the World Wide Web using 
  websites associated with their business. Most online services are implemented as web applications. Online banking, search engines, email applications, 
  and social networks are just a few examples of such web services. Web content is generated in real-time by a software application running on the server-side. 
  Web servers are a critical component of web infrastructure. A single vulnerability in a web server’s configuration may lead to a security breach on websites. 
  This makes web server security critical to the normal functioning of an organization. Hackers attack web servers to steal credentials, passwords, and business 
  information. They do this using DoS, DDoS, DNS server hijacking, DNS amplification, directory traversal, Man-in-the-Middle (MITM), sniffing, phishing, website 
  defacement, web server misconfiguration, HTTP response splitting, web cache poisoning, SSH brute force, web server password cracking, and other methods. 
  Attackers can exploit a poorly configured web server with known vulnerabilities to compromise the security of the web application. A leaky server can harm an 
  organization. In the area of web security, despite strong encryption on the browser-server channel, web users still have no assurance about what happens at 
  the other end. This module presents a security application that augments web servers with trusted co-servers composed of high-assurance secure co-processors, 
  conﬁgured with a publicly known guardian program. Web users can then establish their authenticated, encrypted channels with a trusted co-server, which can 
  act as a trusted third party in the browser-server interaction. Systems are constantly being attacked, so IT security professionals need to be aware of the 
  common attacks on web server applications. A penetration (pen) tester or ethical hacker for an organization must provide security to the company’s web server. 
  This includes performing checks on the web server for vulnerabilities, misconfigurations, unpatched security flaws, and improper authentication with external 
  systems.</p>
<h2>Footprint a webserver</h2>
<p>The first step of hacking web servers for a professional ethical hacker or pen tester is to collect as much information as possible about the target web 
  server and analyze the collected information in order to find lapses in its current security mechanisms. The main purpose is to learn about the web server’s 
  remote access capabilities, its ports and services, and other aspects of its security. The information obtained in this step helps in assessing the security 
  posture of the web server. Footprinting may involve searching the Internet, newsgroups, bulletin boards, etc. for gathering information about the target 
  organization’s web server. There are also tools such as Whois.net and Whois Lookup that extract information such as the target’s domain name, IP address, 
  and autonomous system number. Web server fingerprinting is an essential task for any penetration tester. Before proceeding to hack or exploit a webserver, 
  the penetration tester must know the type and version of the webserver as most of the attacks and exploits are specific to the type and version of the 
  server being used by the target. These methods help any penetration tester to gain information and analyze their target so that they can perform a thorough 
  test and can deploy appropriate methods to mitigate such attacks on the server. An ethical hacker or penetration tester must perform footprinting to detect 
  the loopholes in the web server of the target organization. This will help in predicting the effectiveness of additional security measures for strengthening 
  and protecting the web server of the target organization. The labs in this exercise demonstrate how to footprint a web server using various footprinting tools 
  and techniques.</p>
<h2>Banner Grabbing</h2>
<h2>NetCat</h2>
<p><ol>
  <ul>nc -vv www.website.com 80</ul>
  <ul>GET / HTTP/1.0</ul>
</ol></p>
<h2>Telnet</h2>
<p><ol>
  <ul>telnet www.website.com 80</ul>
  <ul>GET / HTTP/1.0</ul>
</ol></p>
<p>Telnet will perform the banner grabbing and gather information such as:</p>
<p><ol>
  <ul>content type</ul>
  <ul>last modified date</ul>
  <ul>accept ranges</ul>
  <ul><a target=_blank href=https://en.wikipedia.org/wiki/HTTP_ETag>ETag</a></ul>
  <ul>Server information</ul>
</ol></p>
<h2>Enumerate Web Server Information using Nmap Scripting Engine (NSE)</h2>
<p>The web applications that are available on the Internet may have vulnerabilities. Some hackers’ attack strategies may need the Administrator role on your 
  server, but sometimes they simply need sensitive information about the server. Utilizing Nmap and http-enum.nse content returns a diagram of those 
  applications, registries, and records uncovered. This way, it is possible to check for vulnerabilities or abuses in databases. Through this technique, 
  it is possible to discover genuine (and extremely dumb) security imperfections on a site such as some sites (like WordPress and PrestaShop) that maintain 
  accessibility to envelopes that ought to be erased once the task has been settled. Once you have identified a vulnerability, you can discover a fix for it.
Nmap, along with Nmap Scripting Engine, can extract a lot of valuable information from the target web server. In addition to Nmap commands, Nmap Scripting 
  Engine (NSE)provides scripts that reveal various useful information about the target web server to an attacker.</p>
<p><ol>
  <ul>nmap -sV --script=http-enum [target website]</ul>
</ol></p>
<p>The next step is to discover the hostnames that resolve the targeted domain</p>
<p><ol>
  <ul>nmap --script hostmap-bfk -script-args hostmap-bfk.prefix=hostmap- www.goodshopping.com</ul>
</ol></p>
<p>Perform an HTTP trace on the targeted domain</p>
<p><ol>
  <ul>nmap --script http-trace -d www.goodshopping.com</ul>
</ol></p>
<p>This script will detect a vulnerable server that uses the TRACE method by sending an HTTP TRACE request that shows if the method is enabled or not.</p>
<p>Now, check whether Web Application Firewall is configured on the target host or domain</p>
<p><ol>
  <ul>nmap -p80 --script http-waf-detect www.goodshopping.com</ul>
</ol></p>
<p>This command will scan the host and attempt to determine whether a web server is being monitored by an IPS, IDS, or WAF. This command will probe the 
  target host with malicious payloads and detect the changes in the response code.</p>
<h1>Detect vulnerable services</h1>
<p>Open a Terminal window with superuser privileges</p>
<p><ol>
  <ul>nmap -sV -sC 10.10.1.9</ul>
</ol></p>
<p>This command shows the running services and versions. This means Nmap will try to determine the version of the services running on open ports. 
  -sC option enables the use of default scripts in the Nmap Scripting Engine (NSE). These scripts perform various tasks like service detection, 
  vulnerability detection, and more.</p>
<p>From the result we can see that port 8080 is open and Apache Tomcat/Coyote 1.1 server is running on the target system. Upon investigation we can see 
  that Apache is vulnerable to Remote Code Execution (RCE) attack. Now we wil use searchsploit to find the vulnerabilities pertaining to RCE attack on the 
  target server.</p>
<p><ol>
  <ul>searchsploit -t Apache RCE</ul>
</ol></p>
<p>This will show the RCE vulnerabilities on the Apache server.</p>
<h2>Perform Web Server Footprinting and Attacks using ShellGPT</h2>
<p>Web server footprinting and subsequent attacks are critical steps in penetration testing or ethical hacking to assess the security posture of a 
  target organization. ShellGPT, an AI-driven tool, enhances these processes by automating information gathering, fingerprinting, and vulnerability 
  identification tasks. Here we will use ShellGPT to perform Webserver footprinting and attacks using ShellGPT. The commands generated by ShellGPT 
  may vary depending on the prompt used and the tools available on the machine. Due to these variables, the output generated by ShellGPT might differ 
  from what is shown in the screenshots. These differences arise from the dynamic nature of the AI's processing and the diverse environments in which 
  it operates. As a result, you may observe differences in command syntax, execution, and results while performing this lab task.</p>
<p><ol>
  <ul>sgpt --shell "perform a directory traversal on target url https://certifiedhacker.com using gobuster"</ul>
  <ul>sgpt --shell "perform directory traversal on 192.168.2.196 using dirb"</ul>
</ol></p>
<p><b>Gobuster</b> is a tool used to brute-force: URIs (directories and files) in web sites, DNS subdomains (with wildcard support), Virtual Host names on 
  target web servers, Open Amazon S3 buckets, Open Google Cloud buckets and TFTP servers. Gobuster is useful for pentesters, ethical hackers and 
  forensics experts. It also can be used for security tests.</p>
<p><b>DIRB</b> is a Web Content Scanner. It looks for existing (and/or hidden) Web Objects. It basically works by launching a dictionary based attack against a 
  web server and analyzing the responses.</p>
  <p><ol>
    <ul>sgpt --shell "perform webserver footprinting on 192.168.2.196"</ul>
    <ul>sgpt --shell "use nmap, whatweb and nikto to perform webserver footprinting on 192.168.2.196"</ul>
  </ol></p>
  <p>Ultimate goal is that nmap, whatweb and nikto will be started to footprint the web server.</p>
<h1>Subdomain discovery</h1>
<p>Sublist3r is a python tool designed to enumerate subdomains of websites using OSINT(Open Source Intelligence). It helps penetration testers and bug 
 hunters collect and gather subdomains for the domain they are targeting. Sublist3r enumerates subdomains using many search engines such as Google, Yahoo, 
 Bing, Baidu, and Ask. Sublist3r also enumerates subdomains using Netcraft, Virustotal, ThreatCrowd, DNSdumpster, and ReverseDNS. The tool is wordlist-based, 
 which means it will use its internal wordlist to attempt to check if the subdomain truly exists. Sublist3r is available in Kali Linux and can be installed 
 using the apt-get command.</p>
<p><ol>
 <ul>sgpt --shell "use sublist3r on shell.com"</ul>
 <ul>sgpt --shell "sublist3r amsterdam.nl output to subdomains.txt and use nmap to check for open port 21 on each result found"</ul>
</ol></p>
